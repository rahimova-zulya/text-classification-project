# Text Classification of Russian News (Culture, Sports, Economics)  
# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π (–ö—É–ª—å—Ç—É—Ä–∞, –°–ø–æ—Ä—Ç, –≠–∫–æ–Ω–æ–º–∏–∫–∞)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3-orange)

---

## üá¨üáß English

### Project Description
This project focuses on classifying Russian news texts into three topics: **Culture, Sports, and Economics**.  
We compared **7 machine learning and deep learning models**, performed comprehensive data preprocessing, hyperparameter tuning, and visual analysis.

**Key steps:**
- Text cleaning and lemmatization (removal of numbers, stop words, Latin characters; preservation of abbreviations and short meaningful words).
- Class balancing (3333 texts per class, total ~10k).
- Training and tuning of 7 models:
  - Classical: LogisticRegression, SVM, RandomForest, MultinomialNB, KNN.
  - Deep learning:  ruBERT-tiny + LR, SentenceTransformers + LR.
- Detailed analysis: confusion matrices, per‚Äëclass precision/recall, ROC curves, feature importance, learning curves, PCA/t‚ÄëSNE, word clouds.
- Final comparison and selection of the best model.

### Results

| Model | Test F1 (macro) | Training time (min) |
|-------|-----------------|---------------------|
| **LogisticRegression + TF-IDF (optimized)** | **0.9875** | 0.77 |
| SVM + TF-IDF (lightning) | 0.9860 | 1.56 |
| MultinomialNB + TF-IDF | 0.9840 | 2.97 |
| RandomForest + TF-IDF | 0.9835 | 2.90 |
| SentenceTransformers + LR | 0.9820 | 31.62 |
| KNN + TF-IDF (optimized) | 0.9800 | 1.70 |
| ruBERT-tiny + LR | 0.9595 | 2.72 |

**Best model:** LogisticRegression + TF-IDF (C=10, max_features=7000) with F1‚Äëmacro = **0.9875** and training time under 30 seconds.

Visualization Examples / –ü—Ä–∏–º–µ—Ä—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π

### Confusion Matrix (LogisticRegression) / –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (–ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è)
![Confusion Matrix](images/logReg_confusion_matrix.png)

### Feature Importance (LogisticRegression) / –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è)
![Feature Importance](images/logReg_top10_features.png)

### PCA and t‚ÄëSNE (LogisticRegression) / PCA –∏ t‚ÄëSNE (–ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è)
![PCA t-SNE](images/logReg_pca_tsne.png)

### Learning curve (LogisticRegression) / –ö—Ä–∏–≤–∞—è –æ–±—É—á–µ–Ω–∏—è (–ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è)
![Learning curve](images/learning_curve_logReg.png)

### Word Clouds / –û–±–ª–∞–∫–∞ —Å–ª–æ–≤
![Word Clouds](images/word_clouds.png)
![Word Cloud](images/word_cloud_all.png)

### Learning Time of all models / –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
![Learning Time](images/learning_time.png)

### Model Comparison / –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
![Model Comparison](images/model_comparison.png)

### Technologies Used
- **Python** (3.8+)
- **scikit-learn** ‚Äì models, metrics, GridSearch/RandomizedSearch
- **NLTK** ‚Äì stop words
- **Transformers**, **SentenceTransformers** ‚Äì embeddings
- **Matplotlib**, **Seaborn**, **WordCloud** ‚Äì visualization
- **Pandas**, **NumPy** ‚Äì data manipulation
- **Joblib** ‚Äì model persistence

### Dataset
The dataset `df_lemmatized.csv` is **not included** in this repository due to its size ( > 100 MB).  
You can download it from Google Drive: [Download dataset](https://drive.google.com/file/d/1OaZAMZzWQTkkpVTk3JlHbfLLyLNrwhyF/view?usp=sharing)

### How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/rahimova-zulya/text-classification-project.git
   cd text-classification-project
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Launch Jupyter Notebook:
   ```bash
   jupyter notebook Rakhimova_Text_Classifier_7_models.ipynb
   ```

License
This project is licensed under the MIT License ‚Äì see the LICENSE file for details.

## üá∑üá∫ –†—É—Å—Å–∫–∏–π

### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
–ü—Ä–æ–µ–∫—Ç –ø–æ—Å–≤—è—â—ë–Ω –∑–∞–¥–∞—á–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ —Ç—Ä—ë–º —Ç–µ–º–∞—Ç–∏–∫–∞–º: **–ö—É–ª—å—Ç—É—Ä–∞, –°–ø–æ—Ä—Ç, –≠–∫–æ–Ω–æ–º–∏–∫–∞**.  
–ë—ã–ª–æ –ø—Ä–æ–≤–µ–¥–µ–Ω–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ **7 –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –∏ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è**, –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –ø–æ–ª–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö, –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑.

**–û—Å–Ω–æ–≤–Ω—ã–µ —ç—Ç–∞–ø—ã:**
- –û—á–∏—Å—Ç–∫–∞ –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤ (—É–¥–∞–ª–µ–Ω–∏–µ —á–∏—Å–µ–ª, —Å—Ç–æ–ø‚Äë—Å–ª–æ–≤, –ª–∞—Ç–∏–Ω–∏—Ü—ã; —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä –∏ –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤).
- –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ (–ø–æ 3333 —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∫–ª–∞—Å—Å, –≤—Å–µ–≥–æ ~10k, –∏–∑–Ω–∞—á–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç - 187 —Ç—ã—Å—è—á —Ç–µ–∫—Å—Ç–æ–≤).
- –û–±—É—á–µ–Ω–∏–µ –∏ —Ç—é–Ω–∏–Ω–≥ 7 –º–æ–¥–µ–ª–µ–π:
  - –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ: LogisticRegression, SVM, RandomForest, MultinomialNB, KNN.
  - –ì–ª—É–±–æ–∫–∏–µ: ruBERT‚Äëtiny + LR, SentenceTransformers + LR.
- –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑: –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫, precision/recall –ø–æ –∫–ª–∞—Å—Å–∞–º, ROC‚Äë–∫—Ä–∏–≤—ã–µ, –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∫—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è, PCA/t‚ÄëSNE, –æ–±–ª–∞–∫–∞ —Å–ª–æ–≤.
- –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏.

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

| –ú–æ–¥–µ–ª—å | –¢–µ—Å—Ç–æ–≤—ã–π F1 (macro) | –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (–º–∏–Ω) |
|--------|---------------------|----------------------|
| **LogisticRegression + TF‚ÄëIDF (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è)** | **0.9875** | 0.49 |
| SVM + TF‚ÄëIDF (lightning) | 0.9860 | 1.53 |
| MultinomialNB + TF‚ÄëIDF | 0.9840 | 3.13 |
| RandomForest + TF‚ÄëIDF | 0.9835 | 3.01 |
| SentenceTransformers + LR | 0.9820 | 36.42 |
| KNN + TF‚ÄëIDF (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è) | 0.9800 | 1.67 |
| ruBERT‚Äëtiny + LR | 0.9595 | 3.07 |

**–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å:** LogisticRegression + TF‚ÄëIDF (C=10, max_features=7000) —Å F1‚Äëmacro = **0.9875** –∏ –≤—Ä–µ–º–µ–Ω–µ–º –æ–±—É—á–µ–Ω–∏—è –º–µ–Ω–µ–µ 30 —Å–µ–∫—É–Ω–¥.

### –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
- **Python** (3.8+)
- **scikit‚Äëlearn** ‚Äì –º–æ–¥–µ–ª–∏, –º–µ—Ç—Ä–∏–∫–∏, GridSearch/RandomizedSearch
- **NLTK** ‚Äì —Å—Ç–æ–ø‚Äë—Å–ª–æ–≤–∞
- **Transformers**, **SentenceTransformers** ‚Äì —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
- **Matplotlib**, **Seaborn**, **WordCloud** ‚Äì –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- **Pandas**, **NumPy** ‚Äì –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
- **Joblib** ‚Äì —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

### –î–∞—Ç–∞—Å–µ—Ç
–§–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ `df_lemmatized.csv` **–Ω–µ –≤–∫–ª—é—á—ë–Ω** –≤ —ç—Ç–æ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏–∑-–∑–∞ –±–æ–ª—å—à–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ ( > 100 –ú–ë).  
–í—ã –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å –µ–≥–æ —Å Google –î–∏—Å–∫–∞: [–°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç](https://drive.google.com/file/d/1OaZAMZzWQTkkpVTk3JlHbfLLyLNrwhyF/view?usp=sharing)

### –ó–∞–ø—É—Å–∫ –ø—Ä–æ–µ–∫—Ç–∞

1. –°–∫–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:
   ```bash
   git clone https://github.com/rahimova-zulya/text-classification-project.git
   cd text-classification-project
   ```
2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
   ```bash
   pip install -r requirements.txt
   ```
3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ Jupyter Notebook:
   ```bash
   jupyter notebook Rakhimova_Text_Classifier_7_models.ipynb
   ```
   
–õ–∏—Ü–µ–Ω–∑–∏—è
–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ–¥ –ª–∏—Ü–µ–Ω–∑–∏–µ–π MIT ‚Äì –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –≤ —Ñ–∞–π–ª–µ LICENSE.
